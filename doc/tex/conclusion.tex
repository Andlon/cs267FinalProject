
We tried both a communication and computational optimal implementation for our empirical variogram calculation. We saw that the computational optimal implementation was better suited for our application given that computation was a greater burden than communication. We extrapolated that the large data set (see Figure~\ref{fig:herten}) would take one minute on 10 nodes (240 processors), which allows for a feasible application of our implementation in geostatistical analysis of the data set, which before now was not possible.

The implementation has room for improvement. One obvious improvement is to extend the symmetric algorithm \ref{alg:compopt} to take a replication parameter like algorithm \ref{alg:commopt} to improve communication. This would also be likely to have the handy benefit of also improving what we measured as input reading for larger number of processors, as this part of the implementation includes an all-reduce, which doesn't scale very well for a large number of processors. Introducing a replication factor $c$ means that you reduce the number of processors involved in the all-reduce by a factor of $c$, since only team leaders need to determine global bounds. Moreover, our current implementation reduces the bounds by a series of non-asynchronous calls to all-reduce. This can be improved by either making the individual collective calls asynchronous, or making a custom reduction operator for a custom struct that holds the bounding box. Which one is faster might be dependent on the MPI implementation used, and would need to be tested.

However, as pointed out throughout the article, for any realistic use case, computation is still dominant. To elaborate on that point, consider the fact that obtaining a larger number of processors usually takes a longer time to obtain access to through queue sytems, and so in practice you would likely want to use the smallest number of processors that gives you the result in a reasonable time. Thus we argue that it would likely be a better time investment to look into shaving off constant factors of time spent by investigating how features like vectorization, data alignment and cache utilization can be leveraged to improve the computational speed of our kernel.

Now that the empirical variogram of this data set can be calculated, it can have a variogram model fitted to it and random fields can be generated fitting the same spatial pattern of the geological heterogeneity, allowing for more accurate groundwater models. This code will be used for future research involving this large data set. 

Additional variogram features will be added, for example directional variograms. Currently, an 'omni-directional' variogram is calculated by our code because it does not consider the angle between the points, only the distance. The modification would include calculating sines and cosines for each pair based on the differences of the coordinates of the points in the pair. The result of the program would be the current $\hat{\gamma}(h)$ plus subsets of it like $\hat{\gamma}_x(h)$ which would only include pairs of points that are within a specified tolerance angle of the x-plane, called a 'direction' variogram. Another feature would be supporting three-dimensional fields. Our 10 test cases were all two-dimensional because the \texttt{gstat} package has known bugs for three-dimensional data and could not be used a reference for correctness. The only modification we need in our code to support three-dimensional data is to read in an additional column from the file and add a third dimension to the distance calculation. The algorithm itself will not change because all unique pairs will still be considered, but subsets of them will also be considered in the directional variograms. 

%%maybe mention how we could improve the file reading?